{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "latex"
        },
        "id": "n_-3Y34jBzv-"
      },
      "source": [
        "# DEEP PROJECT NOTEBOOK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-srm4KrABzv_"
      },
      "source": [
        "Project Description, issues, pictures, present CLIP, COOP and CoCa briefly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwomUafGBzv_"
      },
      "source": [
        "# Project Setup\n",
        "\n",
        "To run this notebook, you need to install the required dependencies. You can do this by running the following command in your terminal:\n",
        "\n",
        "# Step 1\n",
        "Clone repo and its submodules\n",
        "# Step 2\n",
        "Download project libraries\n",
        "# Step 3\n",
        "Import libraries\n",
        "# Step 4\n",
        "Download resources:\n",
        "- ImageNetA\n",
        "- ImageNetV2\n",
        "- CoOp pretrained weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/rogergheser/DS-DLProject.git\n",
        "%cd DS-DLProject/\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "DpUAkaWBB9d-",
        "outputId": "c3fee167-d5c1-40f6-e495-ce2d2bda8f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "augmix.py\tcoca.py        loaders.py\t results\t     tmp\n",
            "augmix_test.py\tCOOP\t       notebook.ipynb\t runs\t\t     TPT\n",
            "CLIP\t\tcoop_train.py  py_vars.py\t stats.py\t     tpt_eval.py\n",
            "coca_model.py\tice\t       requirements.txt  test_histograms.py  utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "collapsed": true,
        "id": "RFJCNZEEBzv_",
        "outputId": "9fe01532-7ac4-4081-e5ed-7a1ae0e9661b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy==6.2.0 (from -r requirements.txt (line 1))\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gdown==5.2.0 (from -r requirements.txt (line 2))\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Collecting matplotlib==3.8.3 (from -r requirements.txt (line 3))\n",
            "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.26.4 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow==10.3.0 (from -r requirements.txt (line 5))\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex==2024.4.16 (from -r requirements.txt (line 6))\n",
            "  Downloading regex-2024.4.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.31.0)\n",
            "Collecting typing==3.7.4.3 (from -r requirements.txt (line 8))\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==2.3.1 (from -r requirements.txt (line 9))\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.18.1 (from -r requirements.txt (line 10))\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.66.2 (from -r requirements.txt (line 11))\n",
            "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting open_clip_torch (from -r requirements.txt (line 12))\n",
            "  Downloading open_clip_torch-2.26.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.41.2)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy==6.2.0->-r requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 2)) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 2)) (3.15.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 7)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 7)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 7)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 7)) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->-r requirements.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->-r requirements.txt (line 9)) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->-r requirements.txt (line 9)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->-r requirements.txt (line 9)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->-r requirements.txt (line 9)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.3.1 (from torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->-r requirements.txt (line 9))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch->-r requirements.txt (line 12)) (0.23.4)\n",
            "Collecting timm (from open_clip_torch->-r requirements.txt (line 12))\n",
            "  Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 13)) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 13)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 13)) (0.4.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.3->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==5.2.0->-r requirements.txt (line 2)) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1->-r requirements.txt (line 9)) (2.1.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->-r requirements.txt (line 7)) (1.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1->-r requirements.txt (line 9)) (1.3.0)\n",
            "Building wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26306 sha256=4bfab16da52a0a3f4c4cf3cdfbeba9de88e95cbb971f2a4e5c1a4da409d9dd5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/d0/9e/1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n",
            "Successfully built typing\n",
            "Installing collected packages: typing, triton, tqdm, regex, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, matplotlib, gdown, torch, torchvision, timm, open_clip_torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.4\n",
            "    Uninstalling tqdm-4.66.4:\n",
            "      Successfully uninstalled tqdm-4.66.4\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.5.15\n",
            "    Uninstalling regex-2024.5.15:\n",
            "      Successfully uninstalled regex-2024.5.15\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 5.1.0\n",
            "    Uninstalling gdown-5.1.0:\n",
            "      Successfully uninstalled gdown-5.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0+cu121\n",
            "    Uninstalling torchvision-0.18.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ftfy-6.2.0 gdown-5.2.0 matplotlib-3.8.3 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 open_clip_torch-2.26.1 pillow-10.3.0 regex-2024.4.16 timm-1.0.7 torch-2.3.1 torchvision-0.18.1 tqdm-4.66.2 triton-2.3.1 typing-3.7.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "tqdm",
                  "typing"
                ]
              },
              "id": "727c8334e6e44af4bc733e6759c27100"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DS-DLProject"
      ],
      "metadata": {
        "id": "WIk66VgrKWbD",
        "outputId": "7727eddf-6bf2-4626-c45f-a22f7b008caa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DS-DLProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sRxyKtbvBzwA"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import requests\n",
        "import tarfile\n",
        "import gdown\n",
        "import torch.amp\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "try:\n",
        "    from torchvision.transforms import InterpolationMode\n",
        "    BICUBIC = InterpolationMode.BICUBIC\n",
        "except ImportError:\n",
        "    BICUBIC = Image.BICUBIC\n",
        "\n",
        "from CLIP import clip\n",
        "\n",
        "from COOP.models import OurCLIP\n",
        "from COOP.utils import get_optimizer, get_loss_function, log_values\n",
        "from COOP.functions import training_step, test_step\n",
        "from COOP.dataloader import get_data\n",
        "from loaders import Augmixer\n",
        "from utils import entropy, batch_report, make_histogram\n",
        "from copy import deepcopy\n",
        "\n",
        "DEBUG = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDLoaxjlBzwA"
      },
      "source": [
        "Here we download the imagenet-a dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZtsL9QOqBzwA",
        "outputId": "dec3afc1-7ab2-47b7-af87-942be1222f7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete.\n"
          ]
        }
      ],
      "source": [
        "# Define the URL for the ImageNet-A dataset\n",
        "url_a = \"https://people.eecs.berkeley.edu/~hendrycks/imagenet-a.tar\"\n",
        "url_v2 = \"https://huggingface.co/datasets/vaishaal/ImageNetV2/resolve/main/imagenetv2-matched-frequency.tar.gz\"\n",
        "\n",
        "# Define the local filename to save the dataset\n",
        "local_filename_a = \"imagenet-a.tar\"\n",
        "local_filename_v2 = \"imagenetv2-matched-frequency-format-val.tar\"\n",
        "\n",
        "# download a file from a URL\n",
        "def download_file(url, local_filename):\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(local_filename, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "def extract_tar_file(file_name, output_dir='.'):\n",
        "    with tarfile.open(file_name, 'r') as tar:\n",
        "        tar.extractall(path=output_dir)\n",
        "\n",
        "# Download the imagenet-a dataset\n",
        "download_file(url_a, local_filename_a)\n",
        "\n",
        "extract_tar_file(local_filename_a, './data')\n",
        "\n",
        "# Download the imagenet-v2 dataset\n",
        "download_file(url_v2, local_filename_v2)\n",
        "\n",
        "extract_tar_file(local_filename_v2, './data')\n",
        "\n",
        "# Clean up the tar files\n",
        "os.remove(local_filename_a)\n",
        "os.remove(local_filename_v2)\n",
        "\n",
        "print(\"Download and extraction complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI2ybjKCBzwA"
      },
      "source": [
        "We download the four backbones of COOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OF0vLZujBzwA",
        "outputId": "13e4f2de-e4d2-4cd3-b095-5b9072fc53b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18ypxfd82RR0pizc5MM1ZWDYDk4j0BtPF\n",
            "From (redirected): https://drive.google.com/uc?id=18ypxfd82RR0pizc5MM1ZWDYDk4j0BtPF&confirm=t&uuid=56dae334-0b34-410e-9406-3d24acd4e34e\n",
            "To: /content/DS-DLProject/bin/coop/backbones_COOP.zip\n",
            "100%|██████████| 137M/137M [00:04<00:00, 30.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Create a directory\n",
        "output_dir = './bin/coop'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Download the models from the link given in the original github repository\n",
        "url = 'https://drive.google.com/uc?id=18ypxfd82RR0pizc5MM1ZWDYDk4j0BtPF'\n",
        "output_file = os.path.join(output_dir, 'backbones_COOP.zip')\n",
        "gdown.download(url, output_file, quiet=False)\n",
        "\n",
        "# Path to the downloaded zip file\n",
        "zip_file = os.path.join(output_dir, 'backbones_COOP.zip')\n",
        "\n",
        "# Extract the contents\n",
        "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "os.remove(zip_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mv bin/coop/to_gdrive/* bin/coop/\n",
        "%rmdir bin/coop/to_gdrive/\n",
        "%ls bin/coop"
      ],
      "metadata": {
        "id": "RZVEsizwNqcF",
        "outputId": "e271bce8-76f8-4bbe-e55b-127503e225bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mrn101_ep50_16shots\u001b[0m/  \u001b[01;34mrn50_ep50_16shots\u001b[0m/  \u001b[01;34mvit_b16_ep50_16shots\u001b[0m/  \u001b[01;34mvit_b32_ep50_16shots\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation Details\n"
      ],
      "metadata": {
        "id": "sLI8v-_2OY9E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UChn3ubKBzwA"
      },
      "source": [
        "We use AVGentropy as loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KNEA88IBzwA"
      },
      "outputs": [],
      "source": [
        "def avg_entropy(outputs):\n",
        "    logits = outputs - outputs.logsumexp(dim=-1, keepdim=True) # logits = outputs.log_softmax(dim=1) [N, 1000]\n",
        "    avg_logits = logits.logsumexp(dim=0) - np.log(logits.shape[0]) # avg_logits = logits.mean(0) [1, 1000]\n",
        "    min_real = torch.finfo(avg_logits.dtype).min\n",
        "    avg_logits = torch.clamp(avg_logits, min=min_real)\n",
        "    return -(avg_logits * torch.exp(avg_logits)).sum(dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Csqe-iNbBzwA"
      },
      "source": [
        "Here we implement TTA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NudetjV8BzwA"
      },
      "outputs": [],
      "source": [
        "#! TODO: MAYBE DELETING COST_FUNCTION\n",
        "def tta_net_train(batch, net, optimizer, scaler, cost_function, id2classes, device=\"cuda\", debug=False):\n",
        "    batch_idx, inputs, targets = batch\n",
        "    # Set the network to training mode\n",
        "    net.train()\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # Filter out the predictions with high entropy.\n",
        "    # Calculating the entropy of the predictions\n",
        "    entropies = [entropy(t).item() for t in outputs.softmax(-1)]\n",
        "    # Calculate the threshold for the lowest entropies values\n",
        "    threshold = np.percentile(entropies, 15)\n",
        "    if scaler is None:\n",
        "        outputs = outputs.softmax(-1)\n",
        "        entropies = [0 if val > threshold else val for val in entropies]\n",
        "        indices = torch.nonzero(torch.tensor(entropies)).squeeze(1)\n",
        "        filtered_outputs = outputs[indices]\n",
        "        filtered_inputs = inputs[indices]\n",
        "        avg_predictions = torch.mean(filtered_outputs, dim=0).unsqueeze(0)\n",
        "        prediction_entropy = entropy(avg_predictions).item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # loss = cost_function(avg_predictions, targets)\n",
        "        loss = avg_entropy(filtered_outputs)\n",
        "\n",
        "        loss.backward()\n",
        "        if debug:\n",
        "            if torch.isnan(net.prompt_learner.ctx.grad).any():\n",
        "                print(\"NaN in context tokens gradient\")\n",
        "                raise ValueError(\"NaN in context tokens gradient\")\n",
        "            if torch.isinf(net.prompt_learner.ctx.grad).any():\n",
        "                print(\"Inf in context tokens gradient\")\n",
        "                raise ValueError(\"Inf in context tokens gradient\")\n",
        "\n",
        "        optimizer.step()\n",
        "    else:\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = outputs.softmax(-1)\n",
        "            entropies = [0 if val > threshold else val for val in entropies]\n",
        "            indices = torch.nonzero(torch.tensor(entropies)).squeeze(1)\n",
        "            filtered_outputs = outputs[indices]\n",
        "            filtered_inputs = inputs[indices]\n",
        "            avg_predictions = torch.mean(filtered_outputs, dim=0).unsqueeze(0)\n",
        "            prediction_entropy = entropy(avg_predictions).item()\n",
        "            loss = avg_entropy(filtered_outputs)\n",
        "            scaler.scale(loss).backward()\n",
        "            if debug:\n",
        "                if torch.isnan(net.prompt_learner.ctx.grad).any():\n",
        "                    print(\"NaN in context tokens gradient\")\n",
        "                    raise ValueError(\"NaN in context tokens gradient\")\n",
        "                if torch.isinf(net.prompt_learner.ctx.grad).any():\n",
        "                    print(\"Inf in context tokens gradient\")\n",
        "                    raise ValueError(\"Inf in context tokens gradient\")\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "    if torch.isnan(net.prompt_learner.ctx).any():\n",
        "        print(\"NaN in context tokens\")\n",
        "        raise ValueError(\"NaN in context tokens\")\n",
        "\n",
        "    if torch.isinf(net.prompt_learner.ctx).any():\n",
        "        print(\"Inf in context tokens\")\n",
        "        raise ValueError(\"Inf in context tokens\")\n",
        "    # show batch\n",
        "    if debug:\n",
        "        batch_report(filtered_inputs, filtered_outputs, avg_predictions, targets, id2classes, batch_n=batch_idx)\n",
        "\n",
        "    prediction = avg_predictions.argmax(dim=1)\n",
        "    return loss.item(), prediction, prediction_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHg24vu2BzwA"
      },
      "source": [
        "here we implement tpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbJhlU1SBzwA"
      },
      "outputs": [],
      "source": [
        "def tpt_train_loop(data_loader, net, optimizer, scaler, cost_function, writer, id2classes, device=\"cuda\", debug=False):\n",
        "    samples = 0.0\n",
        "    cumulative_loss = 0.0\n",
        "    cumulative_accuracy = 0.0\n",
        "    top1 = 0\n",
        "    top5 = 0\n",
        "\n",
        "    no_tpt_class_acc = {c: [] for c in id2classes.values()}\n",
        "    tpt_class_acc = {c: [] for c in id2classes.values()}\n",
        "    loss_diff = 0.0\n",
        "\n",
        "    optimizer_state = deepcopy(optimizer.state_dict())\n",
        "\n",
        "    try:\n",
        "        # Disable gradient computation (we are only testing, we do not want our model to be modified in this step!)\n",
        "        pbar = tqdm(data_loader, desc=\"Testing\", position=0, leave=True, total=len(data_loader))\n",
        "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "            # Reset the prompt_learner to its initial state and the optimizer to its initial state\n",
        "            with torch.no_grad():\n",
        "                net.reset()\n",
        "                optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "            # Optimize prompts using TTA and augmentations\n",
        "            # Get prediction without prompt optimization\n",
        "            _loss, no_tpt_prediction, no_tpt_prediction_entropy = tta_net_train((batch_idx, inputs, targets), net, optimizer, scaler, cost_function, id2classes, device=device, debug=debug)\n",
        "            #_loss, no_tpt_prediction, no_tpt_prediction_entropy = 0, torch.tensor(-1), 0\n",
        "\n",
        "            if no_tpt_prediction.item() == targets.item():\n",
        "                no_tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(1)\n",
        "            else:\n",
        "                no_tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(0)\n",
        "\n",
        "            # Evaluate the trained prompts on the single sample\n",
        "            net.eval()\n",
        "            with torch.no_grad():\n",
        "                inputs = inputs[0].unsqueeze(0).to(device)\n",
        "                targets = targets.to(device)\n",
        "                outputs = net(inputs)\n",
        "                loss = cost_function(outputs, targets)\n",
        "                cumulative_loss += loss.item()\n",
        "                samples += 1\n",
        "                prediction = outputs.argmax(dim=1)\n",
        "                prediction_entropy = entropy(prediction).item()\n",
        "\n",
        "                values, predictions = outputs.topk(5)\n",
        "                if prediction == targets:\n",
        "                    top1 += 1\n",
        "                    tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(1)\n",
        "                else:\n",
        "                    tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(0)\n",
        "                    pass\n",
        "                if targets.item() in predictions:\n",
        "                    top5 += (targets.view(-1, 1) == predictions).sum().item()\n",
        "\n",
        "                top1_str = id2classes[prediction.item()]\n",
        "                top5_str = [id2classes[pred] for pred in predictions[0].tolist()]\n",
        "                target_str = id2classes[targets.item()]\n",
        "                loss_diff +=  _loss - loss.item() # comparison of loss with and without TPT\n",
        "                entropy_diff = prediction_entropy - no_tpt_prediction_entropy # comparison of entropy with and without TPT\n",
        "\n",
        "            writer.add_scalar(\"Delta_loss/test\", loss_diff, batch_idx)\n",
        "            writer.add_scalar(\"Delta_entropy/test\", entropy_diff, batch_idx)\n",
        "\n",
        "            pbar.set_postfix(test_loss=loss.item(), top1=top1/samples * 100, top5=top5/samples * 100)\n",
        "            pbar.update(1)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"User keyboard interrupt\")\n",
        "    except Exception:\n",
        "        for c in id2classes.values():\n",
        "            if len(no_tpt_class_acc[c]) == 0 or len(tpt_class_acc[c]) == 0:\n",
        "                continue\n",
        "            no_tpt_acc = sum(no_tpt_class_acc[c]) / len(no_tpt_class_acc[c])\n",
        "            tpt_acc = sum(tpt_class_acc[c]) / len(tpt_class_acc[c])\n",
        "            writer.add_scalar(f\"Class accuracy/{c}\", no_tpt_acc, 0)\n",
        "            writer.add_scalar(f\"Class accuracy/{c}\", tpt_acc, 1)\n",
        "        # TODO plot histogram\n",
        "        raise\n",
        "\n",
        "    pbar.close()\n",
        "    # Log the final values and class accuracies\n",
        "    # create histogram for class accuracies and log it with tensorboard\n",
        "    # Create single histograms for each class with a column for TPT and one for no TPT\n",
        "\n",
        "    no_tpt_accuracies = {}\n",
        "    accuracies = {}\n",
        "\n",
        "    for c in id2classes.values():\n",
        "        if len(no_tpt_class_acc[c]) == 0 or len(tpt_class_acc[c]) == 0:\n",
        "            continue\n",
        "        no_tpt_accuracies[c] = sum(no_tpt_class_acc[c]) / len(no_tpt_class_acc[c])\n",
        "        accuracies[c] = sum(tpt_class_acc[c]) / len(tpt_class_acc[c])\n",
        "\n",
        "    image = make_histogram(no_tpt_accuracies, accuracies, 'No TPT','TPT', save_path=\"results/imagenet_A/plots/accuracy_by_class.png\")\n",
        "    writer.add_image(\"Class accuracies\", image, 0, dataformats=\"HWC\")\n",
        "\n",
        "    return cumulative_loss / samples, cumulative_accuracy / samples * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9-NbRxlBzwB"
      },
      "source": [
        "In the main we load and augment the data, we load CLIP and COOP. We use AdamW as optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7xfAc9WBzwB"
      },
      "outputs": [],
      "source": [
        "def main(\n",
        "    dataset_name=\"imagenet_a\",\n",
        "    backbone=\"RN50\",\n",
        "    device=\"mps\",\n",
        "    batch_size=16,\n",
        "    learning_rate=0.005,\n",
        "    tta_steps=2,\n",
        "    run_name=\"exp5\",\n",
        "    n_ctx=4,\n",
        "    ctx_init=\"a_photo_of_a\",\n",
        "    class_token_position=\"end\",\n",
        "    csc=False,\n",
        "    debug=DEBUG\n",
        "):\n",
        "    print(\"Using manual seed\")\n",
        "    torch.manual_seed(0)\n",
        "    # Create a logger for the experiment\n",
        "    writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n",
        "\n",
        "    # Load the model with its backbone and keep only the preprocess\n",
        "    _, preprocess = clip.load(backbone, device=device)\n",
        "    data_transform = Augmixer(preprocess, batch_size, severity=3)\n",
        "    # Get dataloaders\n",
        "    _, _, test_loader, classnames, id2class = get_data(\n",
        "        dataset_name, 1, data_transform, train_size=0, val_size=0, shuffle=True\n",
        "    )\n",
        "\n",
        "    # Instantiate the network and move it to the chosen device (GPU)\n",
        "    net = OurCLIP(\n",
        "        classnames=classnames,\n",
        "        n_ctx=n_ctx,\n",
        "        ctx_init=ctx_init,\n",
        "        class_token_position=class_token_position,\n",
        "        backbone=backbone,\n",
        "        csc=csc,\n",
        "    ).to(device)\n",
        "\n",
        "    # Load the weights of COOP\n",
        "    load_pretrained_coop(backbone, net)\n",
        "\n",
        "    print(\"Turning off gradients in both the image and the text encoder\")\n",
        "    for name, param in net.named_parameters():\n",
        "        if \"prompt_learner\" not in name:\n",
        "            param.requires_grad_(False)\n",
        "\n",
        "    print(f\"Total parameters: {sum(p.numel() for p in net.parameters()):,}\")\n",
        "    print(\n",
        "        f\"Total trainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\"\n",
        "    )\n",
        "\n",
        "    trainable_param = net.prompt_learner.parameters()\n",
        "    optimizer = torch.optim.AdamW(trainable_param, learning_rate)\n",
        "    if device == 'cuda':\n",
        "        scaler = torch.cuda.amp.GradScaler(init_scale=1000)\n",
        "    else:\n",
        "        scaler = None\n",
        "    # Define the cost function\n",
        "    cost_function = get_cost_function()\n",
        "\n",
        "    print(\"Beginning testing with TPT:\")\n",
        "    test_loss, test_accuracy = tpt_train_loop(test_loader, net, optimizer, scaler, cost_function, writer, id2classes=id2class, device=device, debug=debug)\n",
        "    print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")\n",
        "    # Closes the logger\n",
        "\n",
        "    writer.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dlvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}