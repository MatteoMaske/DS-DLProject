{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# DEEP PROJECT NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting doing all the import necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Setup\n",
    "\n",
    "To run this notebook, you need to install the required dependencies. You can do this by running the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib==3.8.3 (from -r requirements.txt (line 1))\n",
      "  Using cached matplotlib-3.8.3-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pillow==10.3.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 3)) (10.3.0)\n",
      "Requirement already satisfied: regex==2024.4.16 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 4)) (2024.4.16)\n",
      "Collecting torch==2.3.1 (from -r requirements.txt (line 5))\n",
      "  Using cached torch-2.3.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision==0.18.1 (from -r requirements.txt (line 6))\n",
      "  Using cached torchvision-0.18.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm==4.66.2 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 7)) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 1)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 1)) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 5)) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 5)) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 5)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 5)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 5)) (2024.3.1)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch==2.3.1->-r requirements.txt (line 5))\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from tqdm==4.66.2->-r requirements.txt (line 7)) (0.4.6)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->-r requirements.txt (line 5))\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->-r requirements.txt (line 5))\n",
      "  Using cached tbb-2021.13.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.8.3->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from jinja2->torch==2.3.1->-r requirements.txt (line 5)) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from sympy->torch==2.3.1->-r requirements.txt (line 5)) (1.3.0)\n",
      "Using cached matplotlib-3.8.3-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "Using cached torch-2.3.1-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Using cached torchvision-0.18.1-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "Installing collected packages: tbb, intel-openmp, mkl, torch, matplotlib, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.2\n",
      "    Uninstalling torch-2.2.2:\n",
      "      Successfully uninstalled torch-2.2.2\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.8.4\n",
      "    Uninstalling matplotlib-3.8.4:\n",
      "      Successfully uninstalled matplotlib-3.8.4\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.17.2\n",
      "    Uninstalling torchvision-0.17.2:\n",
      "      Successfully uninstalled torchvision-0.17.2\n",
      "Successfully installed intel-openmp-2021.4.0 matplotlib-3.8.3 mkl-2021.4.0 tbb-2021.13.0 torch-2.3.1 torchvision-0.18.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\utente\\Documents\\VitaaTrento\\Anno1Semestre2\\DeepLearning\\DeepProject\\dlvenv\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\utente\\Documents\\VitaaTrento\\Anno1Semestre2\\DeepLearning\\DeepProject\\dlvenv\\Lib\\site-packages\\~atplotlib.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\utente\\Documents\\VitaaTrento\\Anno1Semestre2\\DeepLearning\\DeepProject\\dlvenv\\Lib\\site-packages\\~atplotlib'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\utente\\Documents\\VitaaTrento\\Anno1Semestre2\\DeepLearning\\DeepProject\\dlvenv\\Lib\\site-packages\\~orchvision'.\n",
      "  You can safely remove it manually.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.amp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "\n",
    "from CLIP import clip\n",
    "\n",
    "from COOP.models import OurCLIP\n",
    "from COOP.utils import get_optimizer, get_cost_function, log_values\n",
    "from COOP.functions import training_step, test_step\n",
    "from COOP.dataloader import get_data\n",
    "from loaders import Augmixer\n",
    "from utils import entropy, avg_entropy, load_pretrained_coop, batch_report, make_histogram\n",
    "from copy import deepcopy\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we implement TTA. We use AVGentropy as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tta_net_train(batch, net, optimizer, scaler, cost_function, id2classes, device=\"cuda\", debug=False):\n",
    "    batch_idx, inputs, targets = batch\n",
    "    # Set the network to training mode\n",
    "    net.train()\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # Filter out the predictions with high entropy\n",
    "    entropies = [entropy(t).item() for t in outputs.softmax(-1)]\n",
    "    # Calculate the threshold for the lowest entropies values\n",
    "    threshold = np.percentile(entropies, 15)\n",
    "    if scaler is None:\n",
    "        outputs = outputs.softmax(-1)\n",
    "        entropies = [0 if val > threshold else val for val in entropies]\n",
    "        indices = torch.nonzero(torch.tensor(entropies)).squeeze(1)\n",
    "        filtered_outputs = outputs[indices]\n",
    "        filtered_inputs = inputs[indices]\n",
    "        avg_predictions = torch.mean(filtered_outputs, dim=0).unsqueeze(0)\n",
    "        prediction_entropy = entropy(avg_predictions).item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # loss = cost_function(avg_predictions, targets)\n",
    "        loss = avg_entropy(filtered_outputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        if debug:\n",
    "            if torch.isnan(net.prompt_learner.ctx.grad).any():\n",
    "                print(\"NaN in context tokens gradient\")\n",
    "                raise ValueError(\"NaN in context tokens gradient\")\n",
    "            if torch.isinf(net.prompt_learner.ctx.grad).any():\n",
    "                print(\"Inf in context tokens gradient\")\n",
    "                raise ValueError(\"Inf in context tokens gradient\")\n",
    "\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = outputs.softmax(-1)\n",
    "            entropies = [0 if val > threshold else val for val in entropies]\n",
    "            indices = torch.nonzero(torch.tensor(entropies)).squeeze(1)\n",
    "            filtered_outputs = outputs[indices]\n",
    "            filtered_inputs = inputs[indices]\n",
    "            avg_predictions = torch.mean(filtered_outputs, dim=0).unsqueeze(0)\n",
    "            prediction_entropy = entropy(avg_predictions).item()\n",
    "            loss = avg_entropy(filtered_outputs)\n",
    "            scaler.scale(loss).backward()\n",
    "            if debug:\n",
    "                if torch.isnan(net.prompt_learner.ctx.grad).any():\n",
    "                    print(\"NaN in context tokens gradient\")\n",
    "                    raise ValueError(\"NaN in context tokens gradient\")\n",
    "                if torch.isinf(net.prompt_learner.ctx.grad).any():\n",
    "                    print(\"Inf in context tokens gradient\")\n",
    "                    raise ValueError(\"Inf in context tokens gradient\")\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "    \n",
    "    if torch.isnan(net.prompt_learner.ctx).any():\n",
    "        print(\"NaN in context tokens\")\n",
    "        raise ValueError(\"NaN in context tokens\")\n",
    "    \n",
    "    if torch.isinf(net.prompt_learner.ctx).any():\n",
    "        print(\"Inf in context tokens\")\n",
    "        raise ValueError(\"Inf in context tokens\")\n",
    "    # show batch\n",
    "    if debug:\n",
    "        batch_report(filtered_inputs, filtered_outputs, avg_predictions, targets, id2classes, batch_n=batch_idx)\n",
    "\n",
    "    prediction = avg_predictions.argmax(dim=1)\n",
    "    return loss.item(), prediction, prediction_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we implement tpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpt_train_loop(data_loader, net, optimizer, scaler, cost_function, writer, id2classes, device=\"cuda\", debug=False):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "\n",
    "    no_tpt_class_acc = {c: [] for c in id2classes.values()}\n",
    "    tpt_class_acc = {c: [] for c in id2classes.values()}\n",
    "    loss_diff = 0.0\n",
    "\n",
    "    optimizer_state = deepcopy(optimizer.state_dict())\n",
    "\n",
    "    try:\n",
    "        # Disable gradient computation (we are only testing, we do not want our model to be modified in this step!)\n",
    "        pbar = tqdm(data_loader, desc=\"Testing\", position=0, leave=True, total=len(data_loader))\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            # Reset the prompt_learner to its initial state and the optimizer to its initial state\n",
    "            with torch.no_grad():\n",
    "                net.reset()\n",
    "                optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "            # Optimize prompts using TTA and augmentations\n",
    "            # Get prediction without prompt optimization      \n",
    "            _loss, no_tpt_prediction, no_tpt_prediction_entropy = tta_net_train((batch_idx, inputs, targets), net, optimizer, scaler, cost_function, id2classes, device=device, debug=debug)\n",
    "            #_loss, no_tpt_prediction, no_tpt_prediction_entropy = 0, torch.tensor(-1), 0\n",
    "\n",
    "            if no_tpt_prediction.item() == targets.item():\n",
    "                no_tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(1)\n",
    "            else:\n",
    "                no_tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(0)\n",
    "\n",
    "            # Evaluate the trained prompts on the single sample\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs[0].unsqueeze(0).to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = cost_function(outputs, targets)\n",
    "                cumulative_loss += loss.item()\n",
    "                samples += 1\n",
    "                prediction = outputs.argmax(dim=1)\n",
    "                prediction_entropy = entropy(prediction).item()\n",
    "\n",
    "                values, predictions = outputs.topk(5)\n",
    "                if prediction == targets:\n",
    "                    top1 += 1\n",
    "                    tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(1)\n",
    "                else:\n",
    "                    tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(0)\n",
    "                    pass\n",
    "                if targets.item() in predictions:\n",
    "                    top5 += (targets.view(-1, 1) == predictions).sum().item()\n",
    "\n",
    "                top1_str = id2classes[prediction.item()]\n",
    "                top5_str = [id2classes[pred] for pred in predictions[0].tolist()]\n",
    "                target_str = id2classes[targets.item()]\n",
    "                loss_diff +=  _loss - loss.item() # comparison of loss with and without TPT\n",
    "                entropy_diff = prediction_entropy - no_tpt_prediction_entropy # comparison of entropy with and without TPT\n",
    "                \n",
    "            writer.add_scalar(\"Delta_loss/test\", loss_diff, batch_idx)\n",
    "            writer.add_scalar(\"Delta_entropy/test\", entropy_diff, batch_idx)\n",
    "\n",
    "            pbar.set_postfix(test_loss=loss.item(), top1=top1/samples * 100, top5=top5/samples * 100)\n",
    "            pbar.update(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"User keyboard interrupt\")\n",
    "    except Exception:\n",
    "        for c in id2classes.values():\n",
    "            if len(no_tpt_class_acc[c]) == 0 or len(tpt_class_acc[c]) == 0:\n",
    "                continue\n",
    "            no_tpt_acc = sum(no_tpt_class_acc[c]) / len(no_tpt_class_acc[c])\n",
    "            tpt_acc = sum(tpt_class_acc[c]) / len(tpt_class_acc[c])\n",
    "            writer.add_scalar(f\"Class accuracy/{c}\", no_tpt_acc, 0)\n",
    "            writer.add_scalar(f\"Class accuracy/{c}\", tpt_acc, 1)\n",
    "        # TODO plot histogram\n",
    "        raise\n",
    "        \n",
    "    pbar.close()\n",
    "    # Log the final values and class accuracies\n",
    "    # create histogram for class accuracies and log it with tensorboard\n",
    "    # Create single histograms for each class with a column for TPT and one for no TPT\n",
    "    \n",
    "    no_tpt_accuracies = {}\n",
    "    accuracies = {}\n",
    "\n",
    "    for c in id2classes.values():\n",
    "        if len(no_tpt_class_acc[c]) == 0 or len(tpt_class_acc[c]) == 0:\n",
    "            continue\n",
    "        no_tpt_accuracies[c] = sum(no_tpt_class_acc[c]) / len(no_tpt_class_acc[c])\n",
    "        accuracies[c] = sum(tpt_class_acc[c]) / len(tpt_class_acc[c])\n",
    "    \n",
    "    image = make_histogram(no_tpt_accuracies, accuracies, 'No TPT','TPT', save_path=\"results/imagenet_A/plots/accuracy_by_class.png\")\n",
    "    writer.add_image(\"Class accuracies\", image, 0, dataformats=\"HWC\")\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the main we load and augment the data, we load CLIp and COOP. We use AdamW as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    dataset_name=\"imagenet_a\",\n",
    "    backbone=\"RN50\",\n",
    "    device=\"mps\",\n",
    "    batch_size=16,\n",
    "    learning_rate=0.005,\n",
    "    tta_steps=2,\n",
    "    run_name=\"exp5\",\n",
    "    n_ctx=4,\n",
    "    ctx_init=\"a_photo_of_a\",\n",
    "    class_token_position=\"end\",\n",
    "    csc=False,\n",
    "    debug=DEBUG\n",
    "):\n",
    "    print(\"Using manual seed\")\n",
    "    torch.manual_seed(0)\n",
    "    # Create a logger for the experiment\n",
    "    writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n",
    "\n",
    "    _, preprocess = clip.load(backbone, device=device)\n",
    "    \n",
    "    data_transform = Augmixer(preprocess, batch_size, severity=3)\n",
    "    # Get dataloaders\n",
    "    _, _, test_loader, classnames, id2class = get_data(\n",
    "        dataset_name, 1, data_transform, train_size=0, val_size=0, shuffle=True\n",
    "    )    \n",
    "\n",
    "    # Instantiate the network and move it to the chosen device (GPU)\n",
    "    net = OurCLIP(\n",
    "        classnames=classnames,\n",
    "        n_ctx=n_ctx,\n",
    "        ctx_init=ctx_init,\n",
    "        class_token_position=class_token_position,\n",
    "        backbone=backbone,\n",
    "        csc=csc,\n",
    "    ).to(device)\n",
    "\n",
    "    load_pretrained_coop(backbone, net)\n",
    "\n",
    "    print(\"Turning off gradients in both the image and the text encoder\")\n",
    "    for name, param in net.named_parameters():\n",
    "        if \"prompt_learner\" not in name:\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in net.parameters()):,}\")\n",
    "    print(\n",
    "        f\"Total trainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\"\n",
    "    )\n",
    "\n",
    "    trainable_param = net.prompt_learner.parameters()\n",
    "    optimizer = torch.optim.AdamW(trainable_param, learning_rate)\n",
    "    if device == 'cuda':\n",
    "        scaler = torch.cuda.amp.GradScaler(init_scale=1000)\n",
    "    else:\n",
    "        scaler = None\n",
    "    # Define the cost function\n",
    "    cost_function = get_cost_function()\n",
    "\n",
    "    print(\"Beginning testing with TPT:\")\n",
    "    test_loss, test_accuracy = tpt_train_loop(test_loader, net, optimizer, scaler, cost_function, writer, id2classes=id2class, device=device, debug=debug)\n",
    "    print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")\n",
    "    # Closes the logger\n",
    "    \n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
