{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# DEEP PROJECT NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting doing all the import necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Setup\n",
    "\n",
    "To run this notebook, you need to install the required dependencies. You can do this by running the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ftfy==6.2.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 1)) (6.2.0)\n",
      "Collecting gdown==5.2.0 (from -r requirements.txt (line 2))\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: matplotlib==3.8.3 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 3)) (3.8.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: pillow==10.3.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 5)) (10.3.0)\n",
      "Requirement already satisfied: regex==2024.4.16 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 6)) (2024.4.16)\n",
      "Requirement already satisfied: requests==2.31.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: typing==3.7.4.3 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 8)) (3.7.4.3)\n",
      "Requirement already satisfied: torch==2.3.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 9)) (2.3.1)\n",
      "Requirement already satisfied: torchvision==0.18.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 10)) (0.18.1)\n",
      "Requirement already satisfied: tqdm==4.66.2 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from -r requirements.txt (line 11)) (4.66.2)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from ftfy==6.2.0->-r requirements.txt (line 1)) (0.2.13)\n",
      "Collecting beautifulsoup4 (from gdown==5.2.0->-r requirements.txt (line 2))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from gdown==5.2.0->-r requirements.txt (line 2)) (3.13.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from matplotlib==3.8.3->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from requests==2.31.0->-r requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from requests==2.31.0->-r requirements.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from requests==2.31.0->-r requirements.txt (line 7)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from requests==2.31.0->-r requirements.txt (line 7)) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 9)) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 9)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 9)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 9)) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from torch==2.3.1->-r requirements.txt (line 9)) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from tqdm==4.66.2->-r requirements.txt (line 11)) (0.4.6)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->-r requirements.txt (line 9)) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.1->-r requirements.txt (line 9)) (2021.13.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.8.3->-r requirements.txt (line 3)) (1.16.0)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown==5.2.0->-r requirements.txt (line 2))\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from jinja2->torch==2.3.1->-r requirements.txt (line 9)) (2.1.5)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 2))\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\utente\\documents\\vitaatrento\\anno1semestre2\\deeplearning\\deepproject\\dlvenv\\lib\\site-packages (from sympy->torch==2.3.1->-r requirements.txt (line 9)) (1.3.0)\n",
      "Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, PySocks, beautifulsoup4, gdown\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.12.3 gdown-5.2.0 soupsieve-2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import requests\n",
    "import tarfile\n",
    "import gdown\n",
    "import torch.amp\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    from torchvision.transforms import InterpolationMode\n",
    "    BICUBIC = InterpolationMode.BICUBIC\n",
    "except ImportError:\n",
    "    BICUBIC = Image.BICUBIC\n",
    "\n",
    "from CLIP import clip\n",
    "\n",
    "from COOP.models import OurCLIP\n",
    "from COOP.utils import get_optimizer, get_loss_function, log_values\n",
    "from COOP.functions import training_step, test_step\n",
    "from COOP.dataloader import get_data\n",
    "from loaders import Augmixer\n",
    "from utils import entropy, batch_report, make_histogram\n",
    "from copy import deepcopy\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download the imagenet-a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download and extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# Define the URL for the ImageNet-A dataset\n",
    "url_a = \"https://people.eecs.berkeley.edu/~hendrycks/imagenet-a.tar\"\n",
    "url_v2 = \"https://huggingface.co/datasets/vaishaal/ImageNetV2/resolve/main/imagenetv2-matched-frequency.tar.gz\"\n",
    "\n",
    "# Define the local filename to save the dataset\n",
    "local_filename_a = \"imagenet-a.tar\"\n",
    "local_filename_v2 = \"imagenetv2-matched-frequency-format-val.tar\"\n",
    "\n",
    "# download a file from a URL\n",
    "def download_file(url, local_filename):\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "\n",
    "def extract_tar_file(file_name, output_dir='.'):\n",
    "    with tarfile.open(file_name, 'r') as tar:\n",
    "        tar.extractall(path=output_dir)\n",
    "\n",
    "# Download the imagenet-a dataset\n",
    "download_file(url_a, local_filename_a)\n",
    "\n",
    "extract_tar_file(local_filename_a, './data')\n",
    "\n",
    "# Download the imagenet-v2 dataset\n",
    "download_file(url_v2, local_filename_v2)\n",
    "\n",
    "extract_tar_file(local_filename_v2, './data')\n",
    "\n",
    "# Clean up the tar files\n",
    "os.remove(local_filename_a)\n",
    "os.remove(local_filename_v2)\n",
    "\n",
    "print(\"Download and extraction complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the four backbones of COOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18ypxfd82RR0pizc5MM1ZWDYDk4j0BtPF\n",
      "From (redirected): https://drive.google.com/uc?id=18ypxfd82RR0pizc5MM1ZWDYDk4j0BtPF&confirm=t&uuid=fdd6154e-73ae-4db3-a375-0c5596332929\n",
      "To: c:\\Users\\Matteo\\Desktop\\localProjects\\DS-DLProject\\bin\\coop\\backbones_COOP.zip\n",
      "100%|██████████| 137M/137M [01:11<00:00, 1.92MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Create a directory\n",
    "output_dir = './bin/coop'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# TODO get rid of to_gdrive subfolder\n",
    "# Download the models from the link given in the original github repository\n",
    "url = 'https://drive.google.com/uc?id=18ypxfd82RR0pizc5MM1ZWDYDk4j0BtPF'\n",
    "output_file = os.path.join(output_dir, 'backbones_COOP.zip')\n",
    "gdown.download(url, output_file, quiet=False)\n",
    "\n",
    "# Path to the downloaded zip file\n",
    "zip_file = os.path.join(output_dir, 'backbones_COOP.zip')\n",
    "\n",
    "# Extract the contents\n",
    "with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_dir)\n",
    "\n",
    "os.remove(zip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use AVGentropy as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_entropy(outputs):\n",
    "    logits = outputs - outputs.logsumexp(dim=-1, keepdim=True) # logits = outputs.log_softmax(dim=1) [N, 1000]\n",
    "    avg_logits = logits.logsumexp(dim=0) - np.log(logits.shape[0]) # avg_logits = logits.mean(0) [1, 1000]\n",
    "    min_real = torch.finfo(avg_logits.dtype).min\n",
    "    avg_logits = torch.clamp(avg_logits, min=min_real)\n",
    "    return -(avg_logits * torch.exp(avg_logits)).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we implement TTA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! TODO: MAYBE DELETING COST_FUNCTION\n",
    "def tta_net_train(batch, net, optimizer, scaler, cost_function, id2classes, device=\"cuda\", debug=False):\n",
    "    batch_idx, inputs, targets = batch\n",
    "    # Set the network to training mode\n",
    "    net.train()\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    # Filter out the predictions with high entropy. \n",
    "    # Calculating the entropy of the predictions\n",
    "    entropies = [entropy(t).item() for t in outputs.softmax(-1)]\n",
    "    # Calculate the threshold for the lowest entropies values\n",
    "    threshold = np.percentile(entropies, 15)\n",
    "    if scaler is None:\n",
    "        outputs = outputs.softmax(-1)\n",
    "        entropies = [0 if val > threshold else val for val in entropies]\n",
    "        indices = torch.nonzero(torch.tensor(entropies)).squeeze(1)\n",
    "        filtered_outputs = outputs[indices]\n",
    "        filtered_inputs = inputs[indices]\n",
    "        avg_predictions = torch.mean(filtered_outputs, dim=0).unsqueeze(0)\n",
    "        prediction_entropy = entropy(avg_predictions).item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # loss = cost_function(avg_predictions, targets)\n",
    "        loss = avg_entropy(filtered_outputs)\n",
    "        \n",
    "        loss.backward()\n",
    "        if debug:\n",
    "            if torch.isnan(net.prompt_learner.ctx.grad).any():\n",
    "                print(\"NaN in context tokens gradient\")\n",
    "                raise ValueError(\"NaN in context tokens gradient\")\n",
    "            if torch.isinf(net.prompt_learner.ctx.grad).any():\n",
    "                print(\"Inf in context tokens gradient\")\n",
    "                raise ValueError(\"Inf in context tokens gradient\")\n",
    "\n",
    "        optimizer.step()\n",
    "    else:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = outputs.softmax(-1)\n",
    "            entropies = [0 if val > threshold else val for val in entropies]\n",
    "            indices = torch.nonzero(torch.tensor(entropies)).squeeze(1)\n",
    "            filtered_outputs = outputs[indices]\n",
    "            filtered_inputs = inputs[indices]\n",
    "            avg_predictions = torch.mean(filtered_outputs, dim=0).unsqueeze(0)\n",
    "            prediction_entropy = entropy(avg_predictions).item()\n",
    "            loss = avg_entropy(filtered_outputs)\n",
    "            scaler.scale(loss).backward()\n",
    "            if debug:\n",
    "                if torch.isnan(net.prompt_learner.ctx.grad).any():\n",
    "                    print(\"NaN in context tokens gradient\")\n",
    "                    raise ValueError(\"NaN in context tokens gradient\")\n",
    "                if torch.isinf(net.prompt_learner.ctx.grad).any():\n",
    "                    print(\"Inf in context tokens gradient\")\n",
    "                    raise ValueError(\"Inf in context tokens gradient\")\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "    \n",
    "    if torch.isnan(net.prompt_learner.ctx).any():\n",
    "        print(\"NaN in context tokens\")\n",
    "        raise ValueError(\"NaN in context tokens\")\n",
    "    \n",
    "    if torch.isinf(net.prompt_learner.ctx).any():\n",
    "        print(\"Inf in context tokens\")\n",
    "        raise ValueError(\"Inf in context tokens\")\n",
    "    # show batch\n",
    "    if debug:\n",
    "        batch_report(filtered_inputs, filtered_outputs, avg_predictions, targets, id2classes, batch_n=batch_idx)\n",
    "\n",
    "    prediction = avg_predictions.argmax(dim=1)\n",
    "    return loss.item(), prediction, prediction_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we implement tpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpt_train_loop(data_loader, net, optimizer, scaler, cost_function, writer, id2classes, device=\"cuda\", debug=False):\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "\n",
    "    no_tpt_class_acc = {c: [] for c in id2classes.values()}\n",
    "    tpt_class_acc = {c: [] for c in id2classes.values()}\n",
    "    loss_diff = 0.0\n",
    "\n",
    "    optimizer_state = deepcopy(optimizer.state_dict())\n",
    "\n",
    "    try:\n",
    "        # Disable gradient computation (we are only testing, we do not want our model to be modified in this step!)\n",
    "        pbar = tqdm(data_loader, desc=\"Testing\", position=0, leave=True, total=len(data_loader))\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            # Reset the prompt_learner to its initial state and the optimizer to its initial state\n",
    "            with torch.no_grad():\n",
    "                net.reset()\n",
    "                optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "            # Optimize prompts using TTA and augmentations\n",
    "            # Get prediction without prompt optimization      \n",
    "            _loss, no_tpt_prediction, no_tpt_prediction_entropy = tta_net_train((batch_idx, inputs, targets), net, optimizer, scaler, cost_function, id2classes, device=device, debug=debug)\n",
    "            #_loss, no_tpt_prediction, no_tpt_prediction_entropy = 0, torch.tensor(-1), 0\n",
    "\n",
    "            if no_tpt_prediction.item() == targets.item():\n",
    "                no_tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(1)\n",
    "            else:\n",
    "                no_tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(0)\n",
    "\n",
    "            # Evaluate the trained prompts on the single sample\n",
    "            net.eval()\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs[0].unsqueeze(0).to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = net(inputs)\n",
    "                loss = cost_function(outputs, targets)\n",
    "                cumulative_loss += loss.item()\n",
    "                samples += 1\n",
    "                prediction = outputs.argmax(dim=1)\n",
    "                prediction_entropy = entropy(prediction).item()\n",
    "\n",
    "                values, predictions = outputs.topk(5)\n",
    "                if prediction == targets:\n",
    "                    top1 += 1\n",
    "                    tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(1)\n",
    "                else:\n",
    "                    tpt_class_acc[id2classes[no_tpt_prediction.item()]].append(0)\n",
    "                    pass\n",
    "                if targets.item() in predictions:\n",
    "                    top5 += (targets.view(-1, 1) == predictions).sum().item()\n",
    "\n",
    "                top1_str = id2classes[prediction.item()]\n",
    "                top5_str = [id2classes[pred] for pred in predictions[0].tolist()]\n",
    "                target_str = id2classes[targets.item()]\n",
    "                loss_diff +=  _loss - loss.item() # comparison of loss with and without TPT\n",
    "                entropy_diff = prediction_entropy - no_tpt_prediction_entropy # comparison of entropy with and without TPT\n",
    "                \n",
    "            writer.add_scalar(\"Delta_loss/test\", loss_diff, batch_idx)\n",
    "            writer.add_scalar(\"Delta_entropy/test\", entropy_diff, batch_idx)\n",
    "\n",
    "            pbar.set_postfix(test_loss=loss.item(), top1=top1/samples * 100, top5=top5/samples * 100)\n",
    "            pbar.update(1)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"User keyboard interrupt\")\n",
    "    except Exception:\n",
    "        for c in id2classes.values():\n",
    "            if len(no_tpt_class_acc[c]) == 0 or len(tpt_class_acc[c]) == 0:\n",
    "                continue\n",
    "            no_tpt_acc = sum(no_tpt_class_acc[c]) / len(no_tpt_class_acc[c])\n",
    "            tpt_acc = sum(tpt_class_acc[c]) / len(tpt_class_acc[c])\n",
    "            writer.add_scalar(f\"Class accuracy/{c}\", no_tpt_acc, 0)\n",
    "            writer.add_scalar(f\"Class accuracy/{c}\", tpt_acc, 1)\n",
    "        # TODO plot histogram\n",
    "        raise\n",
    "        \n",
    "    pbar.close()\n",
    "    # Log the final values and class accuracies\n",
    "    # create histogram for class accuracies and log it with tensorboard\n",
    "    # Create single histograms for each class with a column for TPT and one for no TPT\n",
    "    \n",
    "    no_tpt_accuracies = {}\n",
    "    accuracies = {}\n",
    "\n",
    "    for c in id2classes.values():\n",
    "        if len(no_tpt_class_acc[c]) == 0 or len(tpt_class_acc[c]) == 0:\n",
    "            continue\n",
    "        no_tpt_accuracies[c] = sum(no_tpt_class_acc[c]) / len(no_tpt_class_acc[c])\n",
    "        accuracies[c] = sum(tpt_class_acc[c]) / len(tpt_class_acc[c])\n",
    "    \n",
    "    image = make_histogram(no_tpt_accuracies, accuracies, 'No TPT','TPT', save_path=\"results/imagenet_A/plots/accuracy_by_class.png\")\n",
    "    writer.add_image(\"Class accuracies\", image, 0, dataformats=\"HWC\")\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the main we load and augment the data, we load CLIP and COOP. We use AdamW as optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    dataset_name=\"imagenet_a\",\n",
    "    backbone=\"RN50\",\n",
    "    device=\"mps\",\n",
    "    batch_size=16,\n",
    "    learning_rate=0.005,\n",
    "    tta_steps=2,\n",
    "    run_name=\"exp5\",\n",
    "    n_ctx=4,\n",
    "    ctx_init=\"a_photo_of_a\",\n",
    "    class_token_position=\"end\",\n",
    "    csc=False,\n",
    "    debug=DEBUG\n",
    "):\n",
    "    print(\"Using manual seed\")\n",
    "    torch.manual_seed(0)\n",
    "    # Create a logger for the experiment\n",
    "    writer = SummaryWriter(log_dir=f\"runs/{run_name}\")\n",
    "\n",
    "    # Load the model with its backbone and keep only the preprocess\n",
    "    _, preprocess = clip.load(backbone, device=device)\n",
    "    data_transform = Augmixer(preprocess, batch_size, severity=3)\n",
    "    # Get dataloaders\n",
    "    _, _, test_loader, classnames, id2class = get_data(\n",
    "        dataset_name, 1, data_transform, train_size=0, val_size=0, shuffle=True\n",
    "    )    \n",
    "\n",
    "    # Instantiate the network and move it to the chosen device (GPU)\n",
    "    net = OurCLIP(\n",
    "        classnames=classnames,\n",
    "        n_ctx=n_ctx,\n",
    "        ctx_init=ctx_init,\n",
    "        class_token_position=class_token_position,\n",
    "        backbone=backbone,\n",
    "        csc=csc,\n",
    "    ).to(device)\n",
    "\n",
    "    # Load the weights of COOP \n",
    "    load_pretrained_coop(backbone, net)\n",
    "\n",
    "    print(\"Turning off gradients in both the image and the text encoder\")\n",
    "    for name, param in net.named_parameters():\n",
    "        if \"prompt_learner\" not in name:\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in net.parameters()):,}\")\n",
    "    print(\n",
    "        f\"Total trainable parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad):,}\"\n",
    "    )\n",
    "\n",
    "    trainable_param = net.prompt_learner.parameters()\n",
    "    optimizer = torch.optim.AdamW(trainable_param, learning_rate)\n",
    "    if device == 'cuda':\n",
    "        scaler = torch.cuda.amp.GradScaler(init_scale=1000)\n",
    "    else:\n",
    "        scaler = None\n",
    "    # Define the cost function\n",
    "    cost_function = get_cost_function()\n",
    "\n",
    "    print(\"Beginning testing with TPT:\")\n",
    "    test_loss, test_accuracy = tpt_train_loop(test_loader, net, optimizer, scaler, cost_function, writer, id2classes=id2class, device=device, debug=debug)\n",
    "    print(f\"\\tTest loss {test_loss:.5f}, Test accuracy {test_accuracy:.2f}\")\n",
    "    # Closes the logger\n",
    "    \n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
